DATABASE: sps
DATASOURCE_URL: localhost:5432
DATASOURCE_USERNAME: pgsql
DATASOURCE_PASSWORD: pgsql
KAFKA_BOOTSTRAP_SERVERS: kafka-hs:9093
SQLSSLROOT: /opt/app/sqlssl
REDIS_URL: redis-svc:6379
REDIS_USERNAME:
REDIS_PASSWORD: redis_123
#/api/${group-name}/v2/${project-name}
api-prefix: /api/kyyee/v2/${spring.application.name}
debug: false

LOG_PATH: /var/log
logging:
  file:
    path: ${LOG_PATH}
  level:
    root: info

management:
  endpoint:
    health:
      show-details: always
    web:
      base-path: ${api-prefix}/actuator
      exposure:
        include: '*'
server:
  servlet:
    context-path: /
  port: 8080
spring:
  profiles:
    #    active: dev,h2
    active: dev
  aop:
    auto: true
  jackson:
    serialization:
      indent-output: true
  application:
    name: sps
  cache:
    caffeine:
      spec: initialCapacity=50,maximumSize=500,expireAfterAccess=60s
    type: caffeine
  datasource:
    primary:
      continue-on-error: true
      driver-class-name: org.postgresql.Driver
      jdbc-url: jdbc:postgresql://${DATASOURCE_URL}/${DATABASE}?currentSchema=public&sslmode=prefer&sslrootcert=${PGSQLSSLROOT}/root.crt&sslkey=${PGSQLSSLROOT}/pgsql.pk8&sslcert=${PGSQLSSLROOT}/pgsql.crt
      password: ${DATASOURCE_PASSWORD}
      username: ${DATASOURCE_USERNAME}
    secondary:
      continue-on-error: true
      driver-class-name: org.postgresql.Driver
      jdbc-url: jdbc:postgresql://${DATASOURCE_URL}/${DATABASE}?currentSchema=public&sslmode=prefer&sslrootcert=${PGSQLSSLROOT}/root.crt&sslkey=${PGSQLSSLROOT}/pgsql.pk8&sslcert=${PGSQLSSLROOT}/pgsql.crt
      password: ${DATASOURCE_PASSWORD}
      username: ${DATASOURCE_USERNAME}
  flyway:
    enabled: true
    clean-disabled: true
    out-of-order: false
    baseline-on-migrate: true
    validate-on-migrate: false
    encoding: UTF-8
    locations: classpath:db/migration
    schemas: public
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS}
    consumer:
      auto-offset-reset: earliest
      enable-auto-commit: false
      group-id: sps
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      ack-mode: manual
      concurrency: 10
      missing-topics-fatal: false
    producer:
      retries: 3
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
  data:
    redis:
      url: redis://${REDIS_USERNAME}:${REDIS_PASSWORD}@${REDIS_URL}
      timeout: 1000ms
      jedis:
        pool:
          max-active: 100
          max-idle: 10
          max-wait: -1ms
          min-idle: 1
  mvc:
    throw-exception-if-no-handler-found: true
  security:
    user:
      name: admin
      password: 123456
  servlet:
    multipart:
      max-file-size: 1048576000
      max-request-size: 1048576000
  task:
    execution:
      pool:
        core-size: 3
        keep-alive: 60s
        max-size: 20
      thread-name-prefix: spsTask-

# springdoc-openapi项目配置
springdoc:
  swagger-ui:
    # 修改Swagger UI路径
    path: /swagger-ui.html
    # 开启Swagger UI界面
    enabled: true
    tags-sorter: alpha
    operations-sorter: alpha
  api-docs:
    # 修改api-docs路径
    path: /v3/api-docs
    # 开启api-docs
    enabled: true
  group-configs:
    - group: ${spring.application.name}
      # 配置需要生成接口文档的接口路径
      paths-to-match: ${api-prefix}/**
      # 配置需要生成接口文档的扫描包
      packages-to-scan: com.kyyee.sps.controller
# knife4j的增强配置，不需要增强可以不配
knife4j:
  enable: true
  setting:
    language: zh_cn

kyyee:
  error-code-prefix: 201
  log:
    enableLog: true
    url: http://bss-log:80
  service:
    bss-uuv: http://bss-uuv:80
    imss-vx: http://172.20.178.223:9095

  config:
    project-name: springboot-project-seed(application.yml)
    author: kyyee
    email: kyyeeyoung@163.com
  kafka:
    topics:
      - name: user_insert_event
        partitions: 3
        single-replicas: 1
        cluster-replicas: 2
      - name: user_update_event
        partitions: 3
        single-replicas: 1
        cluster-replicas: 2
      - name: user_delete_event
        partitions: 3
        single-replicas: 1
        cluster-replicas: 2
      - name: other_topic
  websocket:
    base-path: ${api-prefix}/websocket/endpoint-wisely
    seed-channel: ${api-prefix}/websocket-channel
